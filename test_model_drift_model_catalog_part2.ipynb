{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a653e7eb",
   "metadata": {},
   "source": [
    "### Model Drift Analysis: load the model from Model Catalog\n",
    "\n",
    "Model Drift Analysis require two dataset containing not only the features (xi) but also the target.\n",
    "\n",
    "It means that, in order to monitor Model's performances and detect Model drift, we need, in some way, to collect data and analyze the results in order to define the \"ground truth\".\n",
    "\n",
    "In this NB I have put a prototype that can be used to **start working on Model Drift**.\n",
    "\n",
    "The dataset used is again the Employee Attrition Data and the model is based on LightGBM (GBM) and Sklearn pipeline.\n",
    "\n",
    "We simulate a Data Drift (adding a \"shift\" to some features) in order to make performances worse.\n",
    "\n",
    "In the First Part of the NB we train a model on a reference dataset and we save the pipeline + the metrics computed on a reference validation dataset.\n",
    "In the second part we reload the model (pipeline) and we re-evaluate the metrics on a new dataset.\n",
    "All the  results are saved in a csv file that can be easily loaded in a DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10da8d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import ads\n",
    "from ads import set_auth\n",
    "\n",
    "# to save to Model Catalog\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_metadata import UseCaseType, MetadataCustomCategory\n",
    "from ads.model.framework.sklearn_model import SklearnModel\n",
    "\n",
    "# used to serialize the pipeline\n",
    "from pickle import dump, load\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import get_scorer, make_scorer, f1_score, roc_auc_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# added to handle with pipelines\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73818b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n"
     ]
    }
   ],
   "source": [
    "# we need ads 2.5.10 or greater\n",
    "print(ads.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b647e1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:~/.oci/config file not exists, default value oci.config.DEFAULT_LOCATION used instead\n"
     ]
    }
   ],
   "source": [
    "# set RP\n",
    "set_auth(auth='resource_principal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55486572",
   "metadata": {},
   "source": [
    "### First Part: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2305396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# definisco le funzioni che identificano le categorie di colonne\n",
    "#\n",
    "def cat_cols_selector(df, target_name):\n",
    "    # the input is the dataframe\n",
    "    \n",
    "    # cols with less than THR values are considered categoricals\n",
    "    THR = 10\n",
    "    \n",
    "    nunique = df.nunique()\n",
    "    types = df.dtypes\n",
    "    \n",
    "    col_list = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if ((types[col] == 'object') or (nunique[col] < THR)):\n",
    "            # print(col)\n",
    "            if col != target_name:\n",
    "                col_list.append(col)\n",
    "    \n",
    "    return col_list\n",
    "\n",
    "def num_cols_selector(df, target_name):\n",
    "    THR = 10\n",
    "    \n",
    "    types = df.dtypes\n",
    "    nunique = df.nunique()\n",
    "    \n",
    "    col_list = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if (types[col] != 'object') and (nunique[col] >= THR): \n",
    "            # print(col)\n",
    "            if col != target_name:\n",
    "                col_list.append(col)\n",
    "    \n",
    "    return col_list\n",
    "\n",
    "def load_as_dataframe(path):\n",
    "    ds = DatasetFactory.open(path,\n",
    "                             target=\"Attrition\").set_positive_class('Yes')\n",
    "\n",
    "    ds_up = ds.up_sample()\n",
    "\n",
    "    # drop unneeded columns\n",
    "    cols_to_drop = ['Directs','name', 'Over18','WeeklyWorkedHours','EmployeeNumber']\n",
    "\n",
    "    ds_used = ds_up.drop(columns=cols_to_drop)\n",
    "    \n",
    "    df_used = ds_used.to_pandas_dataframe()\n",
    "    \n",
    "    # train, test split (lo faccio direttamente sui dataframe)\n",
    "    df_train, df_test = train_test_split(df_used, shuffle=True, test_size=0.2, random_state = 1234)\n",
    "\n",
    "    print(\"# of samples in train set\", df_train.shape[0])\n",
    "    print(\"# of samples in test set\", df_test.shape[0])\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90454467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4f66d8064d49b0b39026f11804e021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples in train set 1972\n",
      "# of samples in test set 494\n",
      "\n",
      "Numerical columns: ['Age', 'SalaryLevel', 'CommuteLength', 'HourlyRate', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike', 'YearsinIndustry', 'YearsOnJob', 'YearsAtCurrentLevel', 'YearsSinceLastPromotion', 'YearsWithCurrManager'] (13)\n",
      "\n",
      "Categorical columns: ['TravelForWork', 'JobFunction', 'EducationalLevel', 'EducationField', 'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'OverTime', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'TrainingTimesLastYear', 'WorkLifeBalance'] (17)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset and do upsampling\n",
    "TARGET = 'Attrition'\n",
    "\n",
    "attrition_path = \"/opt/notebooks/ads-examples/oracle_data/orcl_attrition.csv\"\n",
    "\n",
    "df_train, df_test = load_as_dataframe(attrition_path)\n",
    "\n",
    "X_train, y_train = df_train.drop([TARGET], axis=1), df_train[TARGET]\n",
    "X_test, y_test = df_test.drop([TARGET], axis=1), df_test[TARGET]\n",
    "\n",
    "# uso ancora la classe dataset per fare l'upsampling\n",
    "\n",
    "cat_cols = cat_cols_selector(df_train, TARGET)\n",
    "num_cols = num_cols_selector(df_train, TARGET)\n",
    "\n",
    "print()\n",
    "print(f'Numerical columns: {num_cols} ({len(num_cols)})')\n",
    "print()\n",
    "print(f'Categorical columns: {cat_cols} ({len(cat_cols)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ed004",
   "metadata": {},
   "source": [
    "### Second Part: analysis on a new dataset\n",
    "\n",
    "we load the model from the Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebfbce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.joblib from model directory /tmp/tmp7qp2kift ...\n",
      "Model is successfully loaded.\n",
      "Start loading model.joblib from model directory /tmp/tmp7qp2kift ...\n",
      "Model is successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "# take Model OCID from UI\n",
    "MODEL_OCID = \"ocid1.datasciencemodel.oc1.eu-milan-1.amaaaaaangencdyayr37s6ihur3m7gb2mi2ujl5hfx57rkudm5bzjqy5kcja\"\n",
    "\n",
    "# load ADS model from Model Catalog\n",
    "ads_model = SklearnModel.from_model_catalog(model_id=MODEL_OCID,\n",
    "                                        model_file_name=\"model.joblib\",\n",
    "                                        artifact_dir=tempfile.mkdtemp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1023de14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('preprocessor',\n",
       "  ColumnTransformer(transformers=[('num',\n",
       "                                   Pipeline(steps=[('imputer', SimpleImputer()),\n",
       "                                                   ('standard_scaler',\n",
       "                                                    StandardScaler())]),\n",
       "                                   ['Age', 'SalaryLevel', 'CommuteLength',\n",
       "                                    'HourlyRate', 'MonthlyIncome', 'MonthlyRate',\n",
       "                                    'NumCompaniesWorked', 'PercentSalaryHike',\n",
       "                                    'YearsinIndustry', 'YearsOnJob',\n",
       "                                    'YearsAtCurrentLevel',\n",
       "                                    'YearsSinceLastPromotion',\n",
       "                                    'YearsWithCurrManager']),\n",
       "                                  ('c...\n",
       "                                                    OrdinalEncoder(handle_unknown='use_encoded_value',\n",
       "                                                                   unknown_value=-1))]),\n",
       "                                   ['TravelForWork', 'JobFunction',\n",
       "                                    'EducationalLevel', 'EducationField',\n",
       "                                    'EnvironmentSatisfaction', 'Gender',\n",
       "                                    'JobInvolvement', 'JobLevel', 'JobRole',\n",
       "                                    'JobSatisfaction', 'MaritalStatus',\n",
       "                                    'OverTime', 'PerformanceRating',\n",
       "                                    'RelationshipSatisfaction',\n",
       "                                    'StockOptionLevel', 'TrainingTimesLastYear',\n",
       "                                    'WorkLifeBalance'])])),\n",
       " ('clf',\n",
       "  LGBMClassifier(categorical_feature=[1, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18,\n",
       "                                      20, 21, 22, 24, 25],\n",
       "                 colsample_bytree=0.6662807010605473,\n",
       "                 learning_rate=0.3956180945076651, max_depth=5, n_estimators=123,\n",
       "                 subsample=0.8643855674715297))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the inner Sklearn pipeline\n",
    "pipe = ads_model.estimator\n",
    "\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7889d995",
   "metadata": {},
   "source": [
    "### Simulate some changes in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44bf456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulate a drift in data...\n"
     ]
    }
   ],
   "source": [
    "# simulate some changes in the dataset\n",
    "# we use again the test set, but with a \"Data Drift\"\n",
    "\n",
    "print(\"Simulate a drift in data...\")\n",
    "\n",
    "X_test['SalaryLevel'] = X_test['SalaryLevel'] + 3000\n",
    "X_test['Age'] = X_test['Age'] + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "569b198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set result:\n",
      "Acc: 0.9069, AUC: 0.9619\n"
     ]
    }
   ],
   "source": [
    "# scoring: compute new metrics\n",
    "test_pred = pipe.predict(X_test)\n",
    "test_probas = pipe.predict_proba(X_test)\n",
    "\n",
    "print('Validation set result:')\n",
    "\n",
    "roc_auc = round(roc_auc_score(y_test, test_probas[:,1]), 4)\n",
    "acc = round(accuracy_score(y_test, test_pred), 4)\n",
    "\n",
    "print(f\"Acc: {acc}, AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that metrics are worse if compared to those registered in the model catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4086d1dd",
   "metadata": {},
   "source": [
    "### Getting the reference dataset and mettrics from the Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f2c236d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClientLibrary</td>\n",
       "      <td>ADS</td>\n",
       "      <td>None</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CondaEnvironment</td>\n",
       "      <td>oci://conda_envs@frqap2zhtzbe/conda_environments/cpu/mygeneralml_p37_cpu_/1.0/mygeneralml_p37_cpu_v1_0</td>\n",
       "      <td>The conda environment where the model was trained.</td>\n",
       "      <td>Training Environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CondaEnvironmentPath</td>\n",
       "      <td>oci://conda_envs@frqap2zhtzbe/conda_environments/cpu/mygeneralml_p37_cpu_/1.0/mygeneralml_p37_cpu_v1_0</td>\n",
       "      <td>The URI of the training conda environment.</td>\n",
       "      <td>Training Environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EnvironmentType</td>\n",
       "      <td>published</td>\n",
       "      <td>The conda environment type, can be published or datascience.</td>\n",
       "      <td>Training Environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ModelArtifacts</td>\n",
       "      <td>input_schema.json, test_json_output.json, model.joblib, runtime.yaml, score.py, output_schema.json</td>\n",
       "      <td>The list of files located in artifacts folder.</td>\n",
       "      <td>Training Environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ModelSerializationFormat</td>\n",
       "      <td>joblib</td>\n",
       "      <td>The model serialization format.</td>\n",
       "      <td>Training Profile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SlugName</td>\n",
       "      <td>mygeneralml_p37_cpu_v1_0</td>\n",
       "      <td>The slug name of the training conda environment.</td>\n",
       "      <td>Training Environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>metrics on reference set</td>\n",
       "      <td>{'accuracy': 0.9514, 'roc_auc': 0.9939}</td>\n",
       "      <td>Metrics evaluated on reference dataset</td>\n",
       "      <td>Performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reference dataset</td>\n",
       "      <td>oci://drift_input@frqap2zhtzbe/reference.csv</td>\n",
       "      <td>Reference dataset url. From this dataset have been extracted train/validation dataset</td>\n",
       "      <td>Training and Validation Datasets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Key  \\\n",
       "0             ClientLibrary   \n",
       "1          CondaEnvironment   \n",
       "2      CondaEnvironmentPath   \n",
       "3           EnvironmentType   \n",
       "4            ModelArtifacts   \n",
       "5  ModelSerializationFormat   \n",
       "6                  SlugName   \n",
       "7  metrics on reference set   \n",
       "8         reference dataset   \n",
       "\n",
       "                                                                                                    Value  \\\n",
       "0                                                                                                     ADS   \n",
       "1  oci://conda_envs@frqap2zhtzbe/conda_environments/cpu/mygeneralml_p37_cpu_/1.0/mygeneralml_p37_cpu_v1_0   \n",
       "2  oci://conda_envs@frqap2zhtzbe/conda_environments/cpu/mygeneralml_p37_cpu_/1.0/mygeneralml_p37_cpu_v1_0   \n",
       "3                                                                                               published   \n",
       "4      input_schema.json, test_json_output.json, model.joblib, runtime.yaml, score.py, output_schema.json   \n",
       "5                                                                                                  joblib   \n",
       "6                                                                                mygeneralml_p37_cpu_v1_0   \n",
       "7                                                                 {'accuracy': 0.9514, 'roc_auc': 0.9939}   \n",
       "8                                                            oci://drift_input@frqap2zhtzbe/reference.csv   \n",
       "\n",
       "                                                                             Description  \\\n",
       "0                                                                                   None   \n",
       "1                                     The conda environment where the model was trained.   \n",
       "2                                             The URI of the training conda environment.   \n",
       "3                           The conda environment type, can be published or datascience.   \n",
       "4                                         The list of files located in artifacts folder.   \n",
       "5                                                        The model serialization format.   \n",
       "6                                       The slug name of the training conda environment.   \n",
       "7                                                 Metrics evaluated on reference dataset   \n",
       "8  Reference dataset url. From this dataset have been extracted train/validation dataset   \n",
       "\n",
       "                           Category  \n",
       "0                             Other  \n",
       "1              Training Environment  \n",
       "2              Training Environment  \n",
       "3              Training Environment  \n",
       "4              Training Environment  \n",
       "5                  Training Profile  \n",
       "6              Training Environment  \n",
       "7                       Performance  \n",
       "8  Training and Validation Datasets  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I can get thecustom metrics as a Pandas Dataframe\n",
    "meta_df = ads_model.metadata_custom.to_dataframe()\n",
    "\n",
    "meta_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61fcaa6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'accuracy': 0.9514, 'roc_auc': 0.9939}\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics\n",
    "ref_metrics = meta_df[meta_df['Key'] == \"metrics on reference set\"]['Value'].values[0]\n",
    "\n",
    "ref_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017873e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# il reference dataset:\n",
    "ref_url = meta_df[meta_df['Key'] == \"reference dataset\"]['Value'].values[0]\n",
    "\n",
    "ref_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosi leggo il dataset di riferimento, la cui url Ã¨ presa dai metadati\n",
    "ref_df = pd.read_csv(ref_url)\n",
    "\n",
    "ref_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7992e2de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mygeneralml_p37_cpu_v1_0]",
   "language": "python",
   "name": "conda-env-mygeneralml_p37_cpu_v1_0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
