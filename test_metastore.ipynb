{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a93ab55",
   "metadata": {},
   "source": [
    "### Test Spark with Catalog Metastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14d895f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab4a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse_uri = \"oci://table_managed@frqap2zhtzbe/\"\n",
    "metastore_id = \"ocid1.datacatalogmetastore.oc1.eu-milan-1.amaaaaaangencdya2xwveqfhdqc3srw4rzc5pyz3z36v3n3ys2bt5oxjnuza\"\n",
    "\n",
    "database_name = \"ODSC_DEMO\"\n",
    "table_name = \"CUSTOMER_CHURN\"\n",
    "table_name2 = \"CUSTOMER_CHURN2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "818e04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original file\n",
    "NAMESPACE = \"frqap2zhtzbe\"\n",
    "BUCKET = \"WORKSHOP\"\n",
    "NOME_FILE = \"customer_churn_data.csv\"\n",
    "\n",
    "URL = f\"oci://{BUCKET}@{NAMESPACE}/{NOME_FILE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "776fdcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL Hive integration test1\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_uri) \\\n",
    "    .config(\"spark.hadoop.oracle.dcat.metastore.id\", metastore_id) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fee2377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "input_dataframe = spark.read.option(\"header\", \"true\").csv(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf852410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|   MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "|7590-VHVEG|Female|            0|    Yes|        No|     1|          No|No phone service|            DSL|            No|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|         29.85|       29.85|   No|\n",
      "|5575-GNVDE|  Male|            0|     No|        No|    34|         Yes|              No|            DSL|           Yes|          No|             Yes|         No|         No|             No|      One year|              No|        Mailed check|         56.95|      1889.5|   No|\n",
      "|3668-QPYBK|  Male|            0|     No|        No|     2|         Yes|              No|            DSL|           Yes|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|        Mailed check|         53.85|      108.15|  Yes|\n",
      "|7795-CFOCW|  Male|            0|     No|        No|    45|          No|No phone service|            DSL|           Yes|          No|             Yes|        Yes|         No|             No|      One year|              No|Bank transfer (au...|          42.3|     1840.75|   No|\n",
      "|9237-HQITU|Female|            0|     No|        No|     2|         Yes|              No|    Fiber optic|            No|          No|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|          70.7|      151.65|  Yes|\n",
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_dataframe.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3d41711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hive Session ID = 09500192-97ef-4842-adeb-4557a0e6f13d\n",
      "23/03/21 15:33:43 ERROR CatalogMetastoreClientUtil: Unable to verify presence or read contents of file, will return this as property\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|odsc_demo|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8f353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP DATABASE IF EXISTS {database_name} CASCADE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59332185",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE DATABASE {database_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2838b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataframe.write.mode(\"overwrite\").saveAsTable(f\"{database_name}.{table_name2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a073ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"USE {database_name}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e409563",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728aa8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b44a79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark32_p38_cpu_v2]",
   "language": "python",
   "name": "conda-env-pyspark32_p38_cpu_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
